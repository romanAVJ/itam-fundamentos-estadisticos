---
title: "Parcial-2023 Sofia Gerard cu: 149721 y Román Vélez cu: 165462"
output:
  pdf_document: default
  html_document: default
---

**Entrega:** 10 de octubre antes de las 16:00 horas, por correo electrónico con 
el título fundamentos-parcial, un solo documento (pdf/html) por equipo.

**Instrucciones:**

* Tus respuestas deben ser claras y debes explicar 
los resultados, incluye también tus procedimientos/código de manera ordenada, 
y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas, 
...), revisa la sección de visualización en las notas.

* Se puede realizar individual o en parejas.

* Si tienes preguntas puedes escribirlas en el anuncio de canvas del examen.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, error=TRUE, message = FALSE)

library(tidyverse)
library(nullabor)

SEED <- 8
```

## Pruebas de hipótesis

Nos solicitan hacer un análisis con el objetivo de probar un material nuevo 
para suela de zapatos (el material B) y ver si es comparable con el material
que se usa normalmente (el material A).

Nos dan el siguiente conjunto de datos:

```{r}

# read data 
df_shoes  <- read_csv("datos/zapatos-1.csv")

# look data #
df_shoes |> glimpse() 
```

1. Realiza una prueba de hipótesis visual y describe tus conclusiones (cuál es el
nivel de significancia de la prueba?).

```{r}

set.seed(SEED)
lineup(
    method = null_permute("material"),
    true = df_shoes,
    n = 20
) |> 
mutate(
    material = factor(material)
) |> 
ggplot(aes(material, desgaste, color = material)) +
    geom_boxplot() +
    facet_wrap(~.sample, nrow = 4) +
    theme_minimal() +
    theme(
        axis.text.x = element_text(angle = 90, hjust = 1)
    )

```

```{r}
decrypt("sD0f gCdC En JP2EdEPn ZY")
```
H0 = No existe diferencia en la diferencia de medias del desgaste de los
materiales.
H1 = Existe una diferencia entre las medias de los materiales, en ambas 
direcciones.

Visulamente no podemos reconocer la gráfica con los datos originales, optamos 
por la 11 o 12 y en realidad con el decrypt vimos que estaba en la posición 3. 
Con un nivel de significancia de 1/20 = 0.05. No existe suficiente evidencia para 
rechazar $\mathcal{H}_{0}$.


2. Realiza una prueba de permutaciones para la diferencia de las medias, escribe la hipótesis nula, la hipótesis alterna y tus conclusiones.

```{r}

# permutation test
set.seed(SEED)
df_material_perm  <- lineup(
    method = null_permute("material"),
    true = df_shoes,
    n = 1000
    ) |> 
    mutate( material = str_glue("material_{material}")) |>
    group_by(material, .sample) |>
    summarise(mean_wear = mean(desgaste)) |>
    arrange(.sample, material) |>
    group_by(.sample) |>
    summarise(diff_mean_wear = diff(mean_wear)) 

# get original diff means
stat_diff_means  <- df_shoes |> 
    mutate(material = str_glue("material_{material}")) |>
    group_by(material) |>
    summarise(mean_wear = mean(desgaste)) |>
    arrange(material) |>
    pull(mean_wear) |> 
    diff()

# get empiricial p-value
ecdf_diff_means  <- ecdf(df_material_perm$diff_mean_wear)
stat_diff  <- ecdf_diff_means(stat_diff_means)
p_value  <- 2 * min(stat_diff, 1 - stat_diff)
cat("p-value: ", p_value, "\n") 


# plot diff means in histogram and add density plot add original diff means
df_material_perm |> 
    ggplot(aes(diff_mean_wear)) +
    geom_rect(aes(xmax = Inf, xmin = stat_diff_means, ymin = 0, ymax = Inf), fill = "pink", alpha = 0.01) +
    geom_vline(xintercept = stat_diff_means, color = "darkred", size = 1.5) +
    geom_histogram(aes(y = ..density..), bins = 30, fill = "steelblue", color = "black", alpha = 0.5) +
    geom_density(color = "blue") +
    annotate("text", x = -2, y = 0.4, label = str_glue("pval: {p_value}"), color = "darkred") +
    theme_minimal() +
    ggtitle("Prueba de permutación") +
    labs(x = "Diferencia de medias", y = "Densidad")

```
Se realiza una prueba de permutaciones para la diferencia de las medias. 

H0 = No existe diferencia en la diferencia de medias del desgaste de los
materiales.

H1 = Existe una diferencia entre las medias de los materiales, en ambas 
direcciones. 

El valor-p de esta prueba de hipótesis es 0.706 por lo que no existe suficiente 
evidencia para rechazar H0. Por lo que no podemos decir que existe una 
diferencia entre las medias de los materiales A y B. 


3. Después de discutir con los responsables del proyecto descubrimos que nos 
faltaba conocer detalles del proceso generador de datos: el experimento se realizó asignando al azar un material a uno de sus zapatos y el otro material al otro zapato de cada niño.
¿Cómo incorporas esta información en tu prueba de hipótesis del inciso 2? ¿Cambian
tus conclusiones?

```{r}

# read data
df_shoes2  <- read_csv("datos/zapatos-2.csv")
df_shoes2 |> glimpse()

# do permutation test controlling by kid
set.seed(SEED)
df_material_perm2 <- df_shoes2 |> 
    group_split(niño) |> 
    map_df(~ lineup(null_permute("material"), true = .x, n = 1000)) |> 
    mutate(
        material = str_glue("material_{material}")
        ) |> 
    group_by(material, .sample) |> 
    summarise(mean_wear = mean(desgaste)) |> 
    group_by(.sample) |>
    arrange(.sample, material) |> 
    summarise(diff_mean_wear = diff(mean_wear)) 

# get original diff means
stat_diff_means  <- df_shoes2 |> 
    mutate(material = str_glue("material_{material}")) |>
    group_by(material) |>
    summarise(mean_wear = mean(desgaste)) |>
    arrange(material) |>
    pull(mean_wear) |> 
    diff()

# get empiricial p-value
ecdf_diff_means  <- ecdf(df_material_perm2$diff_mean_wear)
stat_diff  <- ecdf_diff_means(stat_diff_means)
p_value  <- 2 * min(stat_diff, 1 - stat_diff)
cat("p-value: ", p_value, "\n")

# plot diff means in histogram and add density plot add original diff means
df_material_perm2 |> 
    ggplot(aes(diff_mean_wear)) +
    geom_rect(aes(xmax = Inf, xmin = stat_diff_means, ymin = 0, ymax = Inf), fill = "pink", alpha = 0.01) +
    geom_vline(xintercept = stat_diff_means, color = "darkred", size = 1.5) +
    geom_histogram(aes(y = ..density..), bins = 30, fill = "steelblue", color = "black", alpha = 0.5) +
    geom_density(color = "blue") +
    annotate("text", x = 0.3, y = 2, label = str_glue("pval: {round(p_value, 4)}"), color = "darkred") +
    theme_minimal() +
    ggtitle("Prueba de permutación", "Control por niño") +
    labs(x = "Diferencia en medias", y = "Densidad")
```

Al cambiar el proceso generador de datos, cambia la manera de hacer la prueba 
de hipótesis. Se trata de un caso de prueba de permutaciones para muestras 
pareadas. Es decir, debemos verificar para cada niño la diferencia de medias, 
ya que todos los niños tienen ambos materiales.  

Al realizar la prueba de poermutaciones podemos observar que el nuevo valor-p
para el caso de prueba pareada es de 0.01, por lo que existe suficiente 
evidencia para rechazar Ho. 

En conclusión para el caso de pruebas pareadas, existe una diferencia 
entre las medias del desgaste de los materiales. 


## Bootstrap

#### Antecedentes 

En México, las elecciones tienen lugar un domingo, los resultados oficiales 
del proceso se presentan a la población una semana después. A fin de evitar 
proclamaciones de victoria injustificadas durante ese periodo el INE organiza un 
conteo rápido. Un conteo rápido es un procedimiento para estimar, a partir de una muestra 
aleatoria de casillas, el porcentaje de votos a favor de cada opción en la boleta. 

En 2021 se realizó un conteo rápido para estimar los resultados de la [consulta popular 2021](https://ine.mx/conteo-rapido-consulta-popular-2021/) y en los siguientes
incisos estimarán los resultados de la consulta y evaluarán la metodología. 

##### Diseño de la muestra

El diseño utilizado en los conteos rápidos es *muestreo estratificado simple*, 
es decir:

i) se particionan las casillas de la pablación en estratos (cada casilla
pertenece a exactamente un estrato), y 

ii) dentro de cada estrato se usa *muestreo aleatorio* para seleccionar las 
casillas que estarán en la muestra. 

##### Estimación 

Una de las metodolgías de estimación, que se usa en el conteo rápido (tanto de 
elecciones como en consultas) es *estimador de razón combinado*, con
intervalos de 95% de confianza construidos con el método normal y error 
estándar bootstrap. En este ejercicio debes construir intervalos usando este 
procedimiento.

Para cada opción en la consulta (sí/no/nulos) usarás la muestra del conteo rápido
para estimar los resultados de la consulta.

1. Calcula el estimador de razón combinado, para muestreo estratificado la 
fórmula es:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
  donde:

  * $\hat{p}$ es la estimación de la proporción de votos que recibió la opción (ej: *sí*).

  * $Y_{hi}$ es el número total de votos que recibió *la opción* (ej: *sí*)
en la $i$-ésima casillas, que pertence al $h$-ésimo estrato.

  * $X_{hi}$ es el número total de votos en la $i$-ésima casilla, que pertence al 
$h$-ésimo estrato. 

  * $N_h$ es el número total de casillas en el $h$-ésimo estrato.

  * $n_h$ es el número de casillas del $h$-ésimo estrato que se seleccionaron en 
la muestra.


##### Datos 

Necesitarás los siguientes datos:

* Cómputos [aquí](https://computos.cp2021.ine.mx/votos-distrito/mapa)

* Muestra del conteo rápido usada en la estimación [aquí](https://ine.mx/conteo-rapido-consulta-popular-2021/)

```{r}

#### read data ####

# preprocesamiento de tablas de datos
df_computos <- read_delim("datos/20210802-2130_INE-CONSULTA-POPULAR-2021/20210802-2130_COMPUTOS-INE-CP2021.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE, quote = "\'",
    skip = 5) |> 
    rename(ID = CLAVE_MRCP) |> 
    mutate(ESTRATO = str_c(str_pad(ID_ENTIDAD, 2, pad = "0"), 
                            str_pad(ID_DISTRITO_FEDERAL, 2, pad = "0")),
            LISTA_NOMINAL = LISTA_NOMINAL_MRCP, 
            TOTAL = TOTAL_OPINIONES)

df_muestra <- read_delim("https://ine.mx/wp-content/uploads/2021/08/Conteos-ConsPop21-Lista-MuestraCalculo.txt", delim = "|", skip = 1) |> 
  mutate(
    ID_ESTADO = str_pad(ID_ESTADO, 2, pad = "0"),
    SECCION = str_pad(SECCION, 4, pad = "0"),
    ID_CASILLA = str_pad(ID_CASILLA, 2, pad = "0"),
    ID = str_c(ID_ESTADO, SECCION, TIPO_CASILLA, ID_CASILLA)
    ) |> 
  group_by(ESTRATO) |> 
  mutate(n = n()) |> 
  ungroup()
```



```{r}

# create a bootstrap function to get the combined ratio of votes 
get_combined_ratio  <- function(df_population, df_sample){
    # setp 0: get Nh / nh
    df_polling_booths_total  <- df_population |> count(ESTRATO) |> rename(Nh = n)
    df_polling_booths_selected  <- df_sample |> count(ESTRATO) |> rename(nh = n)
    df_polling_booths  <- df_polling_booths_total |> 
        inner_join(df_polling_booths_selected, by = "ESTRATO") |> 
        mutate(Nh_nh = Nh / nh) |> 
        select(ESTRATO, Nh_nh)

    # step 1: get total votes expanded
    total_expanded_votes  <- df_sample |> 
        inner_join(df_polling_booths, by = "ESTRATO") |> 
        mutate(weighted_total_votes = TOTAL * Nh_nh) |> 
        pull(weighted_total_votes) |>
        sum()

    # step 2: get combined ratios expanded by option
    df_total_votes_by_option  <- df_sample |> 
        pivot_longer(c("SI", "NO", "NULOS"), names_to = "OPCION", values_to = "VOTOS") |> 
        inner_join(df_polling_booths, by = "ESTRATO") |>
        mutate(weighted_total_votes = VOTOS * Nh_nh) |> 
        group_by(OPCION) |>
        summarise(combined_ratio = sum(weighted_total_votes) / total_expanded_votes)

    return(df_total_votes_by_option)
}

# look if function works
table_combined_ratios  <- get_combined_ratio(df_computos, df_muestra) # is ok!
# print table in html with percentage format
knitr::kable(
    table_combined_ratios, digits = 4, 
    format.args = list(big.mark = ",", decimal.mark = ".", format = "f"), 
    caption = "Tabla de razones combinadas de votos en la muestra"
    )
```

El estimador de razón combinado para muestreo estratificado (proporcion o gorrro) es:
0.0148 para el caso de "NO".
0.0557 para el caso de "NULOS".
0.9295 para el caso de "SI". 

2. Utiliza **bootstrap** para calcular el error estándar, y reporta tu 
estimación del error.
    + Genera 1000 muestras bootstrap.
    + Recuerda que las muestras bootstrap tienen que tomar en cuenta la 
    metodología que se utilizó en la selección de la muestra original, en este
    caso implica que para cada remuestra debes tomar muestra aleatoria independiente
    dentro de cada estrato.
    
```{r}

# create bootstrap function
svy_boot  <- function(df_population, df_sample){
    # get sample of polling booths BY ESTRATO
    df_sample_by_estrato  <- df_sample |> 
        group_split(ESTRATO) |> 
        map_df(~ slice_sample(
            .x, 
            n = first(.x$n), 
            replace = TRUE)
        )

    # get combined ratio of votes
    df_combined_ratio  <- get_combined_ratio(df_population, df_sample_by_estrato)
    return(df_combined_ratio)
}

# generate bootstrap samples
set.seed(SEED)
N_BOOT  <- 1000
df_bootstrap_combined_ratio  <- map_dfr(1:N_BOOT, ~ svy_boot(df_computos, df_muestra))

# look bootstraps
df_bootstrap_combined_ratio
```


3. Construye un intervalo del 95% de confianza utilizando el método normal. Revisa 
si el supuesto de normalidad es razonable.

```{r}

# get normal confidence interval at 95%
ALPHA  <- 0.05
Z_ALPHA  <- qnorm(1 - ALPHA / 2)

# get confidence interval
table_se_combined_ratio  <- df_bootstrap_combined_ratio |> 
    group_by(OPCION) |> 
    summarise(
        mean = mean(combined_ratio), 
        sd = sd(combined_ratio), # error estándar 
        lower = mean - Z_ALPHA * sd,
        upper = mean + Z_ALPHA * sd
    ) |> 
    mutate(longitud = upper - lower)

table_se_combined_ratio |> 
    knitr::kable(
        digits = 4, 
        format.args = list(big.mark = ",", decimal.mark = ".", format = "f"), 
        caption = "Intervalos de confianza al 95% para las razones combinadas de votos"
        )

```

4. Reporta tus intervalos en una tabla. Compara la longitud de los 3 intervalos y 
describe que observas.

```{r}

# get observed ratios
table_observed_ratios  <- df_computos |> 
    rename(SI = OPINION_SI, NO = OPINION_NO) |>
    pivot_longer(c("SI", "NO", "NULOS"), names_to = "OPCION", values_to = "VOTOS") |> 
    group_by(OPCION) |>
    summarise(VOTOS = sum(VOTOS)) |> 
    ungroup() |>
    mutate(
        PERCENT_VOTOS = VOTOS / sum(VOTOS),
    )

# get relative bias
table_se_combined_ratio |> 
    inner_join(table_observed_ratios, by = "OPCION") |> 
    mutate(
        relative_bias = (mean - PERCENT_VOTOS) / sd
    ) |> 
    knitr::kable(
        digits = 4, 
        format.args = list(big.mark = ",", decimal.mark = ".", format = "f"), 
        caption = "Tabla de sesgo relativo de las razones combinadas de votos"
        )
```


```{r}

df_bootstrap_combined_ratio |> 
    group_split(OPCION) |> 
    map(~ {
        .x |> 
            ggplot(aes(sample = combined_ratio)) +
            geom_qq() + geom_qq_line() +
            theme_minimal() +
            ggtitle(str_glue("QQ-plot para {first(.x$OPCION)}")) +
            labs(x = "Cuantiles teóricos", y = "Cuantiles empíricos") +
            theme(legend.position = "none")
    })



```

En las gráficas de QQ-plot vemos que las colas no coinciden con las de la 
distribución de referencia normal. Para las opciones "NO" y "NULOS, las colas
se encuentran por encima de la normal, con mayor dispersión. Mientras que para
"SI" las colas están por debajo de la normal también, con mayor dispersión.

Adicionalmente tenemos un sesgo relativo al error estándar alto para "NO"
"NULOS" y "SI" (-1.1779, 3.3236, -3.3243) por lo que el método normal para 
el cálculo de intervalos de confianza no parece ser el más adecuado en caso de 
queres estimar en las colas.

5. ¿Tus intervalos contienen los valores observados en los cómputos? Explica los
resultados observados.


```{r}

# plot confidence intervals. use error bars with lower and upper. use percent_votos as point estimate
table_se_combined_ratio |> 
    inner_join(table_observed_ratios, by = "OPCION") |> 
    ggplot(aes(x = OPCION, y = PERCENT_VOTOS, ymin = lower, ymax = upper)) +
    geom_errorbar(width = 0.2) +
    geom_point(color = "darkred") +
    theme_minimal() +
    ggtitle("Intervalos de confianza al 95% para las razones combinadas de votos") +
    labs(x = "Opción", y = "Porcentaje de votos") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    coord_flip() +
    theme(legend.position = "none")




```
En la gráfica anterior podemos observar que "percent_votos" no se encuentra
dentro de los intervalos de confianza paea "SI" y "NULOS". Esto puede deberse a 
que los datos no siguen una distribución que se ajuste bien a los supuestos del 
método normal para calcular el intervalo de confianza, por ende intervalo
resultante puede ser inexacto.


#### Calibración

Selecciona al menos 50 muestras del mismo tamaño y con el mismo diseño que la 
muestra utilizada en el conteo rápido. Esto es, selecciona el 
mismo número de casillas, usando muestreo aleatorio simple dentro de cada estrato.

* Para cada muestra calcula un intervalo del 95% de confianza usando bootstrap.

* Grafica los intervalos y calcula la proporción de ellos que contienen el 
verdadero valor observado. Describe tus observaciones y compara con el intervalo 
obtenido en el ejercicio anterior.

```{r}

# from df_population get 50 samples of size M = length(df_muestra)
# and apply svy_boot to each sample
set.seed(SEED)
N_BOOT  <- 5
N_CI  <- 5
M  <- 1745 # same as the sample size of df_muestra

applyboot  <- function(df_sample, df_population, num_boot=100){
    # get combined ratio of votes
    df_combined_ratio  <- map_dfr(1:num_boot, ~ svy_boot(df_population, df_sample))
    return(df_combined_ratio)
}

df_bootstrap_combined_ratio_calibration  <- map_df(1:N_CI, ~ {
    # apply svy_boot to each sample of size M per polling booth
    df_sample_by_poll  <- df_computos |>
        rename(SI = OPINION_SI, NO = OPINION_NO) |> 
        slice_sample(n = M, replace = TRUE) |>
        # get num of polling booths by ESTRATO
        group_by(ESTRATO) |> 
        mutate(n = n()) |> 
        ungroup() |>
        # apply svy_boot to each polling booth
        applyboot(df_computos, num_boot=N_BOOT) |> 
        group_by(OPCION) |> 
        summarise(
            mean = mean(combined_ratio), 
            sd = sd(combined_ratio), 
            lower = mean - Z_ALPHA * sd, 
            upper = mean + Z_ALPHA * sd
        )
    return(df_sample_by_poll)},
    .id = 'rep'
)

# get the number of times the observed ratio is in the confidence interval
table_calibration  <- df_bootstrap_combined_ratio_calibration |> 
    inner_join(table_observed_ratios, by = "OPCION") |> 
    mutate(
        in_ci = ifelse(lower <= PERCENT_VOTOS & PERCENT_VOTOS <= upper, 1, 0)
    ) |> 
    group_by(OPCION) |> 
    summarise(
        total = n(),
        in_ci = sum(in_ci),
        not_in_ci = total - sum(in_ci),
    ) |> 
    mutate(
        percent_in_ci = in_ci / total,
        percent_not_in_ci = not_in_ci / total
    )
table_calibration

table_calibration |> 
    knitr::kable(
        digits = 4, 
        format.args = list(big.mark = ",", decimal.mark = ".", format = "f"), 
        caption = "Tabla de intervalos de confianza normales"
        )
```

En la tabla anterior vemos que los intervalos no tienen la cobertura real
esperada por lo que no están bien calibrados. 
La proporción observada no se encuentra dentro del intervalo de confianza.
Esto podría deberse a que la muestra está sesgada por votos nulos y 
probablemente a que no se cumple el supuesto de distribución 
simétrica con colas no muy largas. 

Intentaría realizar un muestreo estratificado según los votos nulos para 
abordar el posible sesgo en los datos relacionado con los votos nulos o 
utilizar el método de percentiles para el cálculo de 
los intervalos de confianza.



```{r}

# plot calibration with error bars. add obsered ratio as point estimate. color not_in_ci in red
table_aux  <- df_bootstrap_combined_ratio_calibration |> 
    inner_join(table_observed_ratios, by = "OPCION") |> 
    mutate(
        in_ci = ifelse(lower <= PERCENT_VOTOS & PERCENT_VOTOS <= upper, "yes", "no"),
        rep = factor(as.integer(rep), ordered = TRUE)
    ) 

# graph for each OPCION group
split(table_aux, table_aux$OPCION) |>
    map(~ {
        ggplot(.x, aes(x = rep, ymin = lower, ymax = upper, color = in_ci)) +
            geom_errorbar(width = 0.2) +
            geom_hline(aes(yintercept = PERCENT_VOTOS), color = "gray30", linetype = 2) +
            theme_minimal() +
            ggtitle(str_glue("Calibración de los intervalos de confianza al 95% para {first(.x$OPCION)}")) +
            labs(x = "Opción", y = "Porcentaje de votos") +
            scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
            scale_color_manual(values = c("yes" = "darkgreen", "no" = "darkred")) +
            theme(legend.position = "none")
    }) 

```

#### Análisis Exploratorio

Un voto nulo corresponde a una boleta donde el ciudadano acudió a las urnas
y anuló su voto. 

Antes de contestar los siguiente incisos piensen que rango esperarían ver para 
la proporción de votos nulos en una casilla.

* Describe la distribución de datos nulos en la muestra, y como se relaciona con 
el total de votos, realiza gráficas y describe tus observaciones.

* En la distribución de proporción de nulos se observan datos atípicos, ¿cuál 
crees que sea la razón de estas observaciones extremas? ¿consideras que se
deben eliminar de la muestra antes de realizar la estimación?

```{r}

#from the df_muestra, do an eda for null votes
df_muestra |> glimpse()

#### explore by percentage by poll booth 
df_muestra |> 
    group_by(ESTRATO, ID) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |> 
    ungroup() |>
    ggplot(aes(x = PERCENT_NULL)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "black", alpha = 0.5) +
    geom_density(color = "blue") +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Histograma de porcentaje de votos nulos", "Por casilla") +
    labs(x = "Porcentaje de votos nulos", y = "Densidad")
```

La gráfica anterior representa la distribución del porcentaje de votos nulos 
por casilla, identificadas por las columnas "ESTRATO" y "ID". Se destaca una
distribución asimétrica, donde la mayoría de las casillas exhiben porcentajes
bajos o insignificantes de votos nulos. No obstante, algunas casillas muestran
porcentajes notablemente elevados de votos nulos, superando el 50% por casilla.

```{r}
# is ok
df_muestra |> 
    group_by(ESTRATO, ID) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |> 
    ungroup() |>
    ggplot(aes(x = PERCENT_NULL)) +
    geom_boxplot(fill = "steelblue", color = "black", alpha = 0.5) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Caja y brazos de porcentaje de votos nulos", "Por casilla") +
    labs(x = "Porcentaje de votos nulos", y = "")
```

La gráfica de caja y brazos ilustra una distribución de datos altamente
concentrada en valores pequeños, con cierta variabilidad en los
valores y la presencia de varios valores atípicos. Esta concentración en valores
pequeños sugiere que, aunque prevalece una tendencia hacia la uniformidad en los
datos, con la mayoría de las observaciones siendo pequeñas o de baja magnitud,
existen casillas particulares de interés debido a que muestran más del 50% de 
votos nulos.




```{r}

df_muestra |> 
    group_by(ESTRATO, ID) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |> 
    ungroup() |>
    ggplot(aes(x = PERCENT_NULL)) +
    stat_ecdf() +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Distribución acumulada", "Por casilla") +
    labs(x = "Porcentaje de votos nulos", y = "")
```

La gráfica de distribución acumulada muestra una alta concentración de datos en
valores pequeños, indicando uniformidad en la mayoría de las observaciones.
Sin embargo, también destaca la presencia de valores atípicos, que alteran la 
distribución acumulada, ya que son especialmente notables por superar el 50% de
la acumulación, y que son de interés particular en el análisis de los datos.

```{r}

#### explore by strata
df_muestra |> 
    group_by(ESTRATO) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |>
    ungroup() |>
    ggplot(aes(x = PERCENT_NULL)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "black", alpha = 0.5) +
    geom_density(color = "blue") +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Histograma de porcentaje de votos nulos", "Por estrato") +
    labs(x = "Porcentaje de votos nulos", y = "Densidad")
```


```{r}
# is ok
df_muestra |> 
    group_by(ESTRATO) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |> 
    ungroup() |>
    ggplot(aes(x = PERCENT_NULL)) +
    geom_boxplot(fill = "steelblue", color = "black", alpha = 0.5) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Caja y brazos de porcentaje de votos nulos", "Por estrato") +
    labs(x = "Porcentaje de votos nulos", y = "")
```



```{r}

df_muestra |> 
    group_by(ESTRATO) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |> 
    ungroup() |>
    ggplot(aes(x = PERCENT_NULL)) +
    stat_ecdf() +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Distribución acumulada", "Por estrato") +
    labs(x = "Porcentaje de votos nulos", y = "")
```

Al analizar las gráficas a nivel de estrato, podemos notar patrones similares
a los que observamos al hacerlo por casilla. En otras palabras, encontramos una 
distribución de datos en la que la mayoría de los valores son pequeños o bajos 
en magnitud, pero también identificamos la presencia de valores atípicos. 
Este hallazgo sugiere la existencia de estratos específicos que son de 
particular interés, ya que muestran más del 50% de votos nulos.

```{r}

#### explore by type of polling booth
table_null_by_type_poll_booth  <- df_muestra |> 
    group_by(TIPO_CASILLA) |> 
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    )
knitr::kable(
    table_null_by_type_poll_booth, digits = 4, 
    format.args = list(big.mark = ",", decimal.mark = ".", format = "f"), 
    caption = "Tabla de porcentaje de votos nulos por tipo de casilla"
    )
```

Al realizar el análisis por tipo de casilla B y C (Básica y Contigua), observamos que el porcentaje de votos nulos es significativamente diferente entre estos dos tipos. Tan solo el 1.21% de los votos son nulos en las casillas tipo B, mientras que en las casillas tipo C, el porcentaje de votos nulos es del 8.61%. Esto indica una diferencia marcada en la incidencia de votos nulos entre estos dos tipos de casillas.

```{r}

#### by state
df_muestra |> 
    group_by(ID_ESTADO) |> 
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |> 
    arrange(desc(ID_ESTADO)) |>
    # col plot
    ggplot(aes(ID_ESTADO, PERCENT_NULL)) +
    geom_col(fill = "steelblue", color = "black", alpha = 0.5) +
    scale_y_continuous(labels = scales::percent) +
    theme_minimal() +
    ggtitle("Porcentaje de votos nulos por estado") +
    labs(x = "Estado", y = "Porcentaje de votos nulos") +
    coord_flip()
```

Al analizar el porcentaje de votos nulos a nivel estatal, se observa que algunos estados muestran una concentración significativa de votos nulos. Por lo tanto, sería recomendable realizar un análisis más detallado a nivel estatal, lo que podría incluir el examen de datos históricos sobre preferencias partidarias u otros factores relevantes. Los estados que presentan los mayores porcentajes de votos nulos son los siguientes:

Yucatán (Estado 31)
Guanajuato (Estado 11)
Jalisco (Estado 14)
Oaxaca (Estado 20)
Zacatecas (Estado 32)
Veracruz (Estado 30)
Estos estados destacan por su alto porcentaje de votos nulos y podrían ser objeto de un análisis más profundo para comprender mejor las razones detrás de esta tendencia.


```{r}

#### relationship between null votes and total votes (scatter + loess)
df_muestra |> 
    group_by(ESTRATO, ID) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL),
        TOTAL = sum(TOTAL)
    ) |> 
    ungroup() |> 
    ggplot(aes(x = TOTAL, y = PERCENT_NULL)) +
    geom_point(color = "#46b478", alpha = 0.5) +
    geom_smooth(method = "loess", color = "darkred", se = FALSE) +
    scale_x_continuous(labels = scales::comma, trans = "log2") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1), trans = "sqrt") +
    theme_minimal() +
    ggtitle("Porcentaje de votos nulos vs total de votos", "Por casilla") +
    labs(x = "Total de votos", y = "Porcentaje de votos nulos")

```
Observamos una peculiaridad en la tendencia que muestra el modelo LOESS. 
Se asemeja a lo que se conoce como la "paradoja de Simpson". En este contexto, 
identificamos "grupos" de casillas que muestran una tendencia descendente, 
mientras que, en general, la tendencia es ascendente, como se visualiza en el modelo LOESS.

Nuestra hipótesis es que existe una mayor propensión a observar menos votos
nulos en casillas con un mayor número total de votos. Esto podría explicarse 
mediante la aplicación de la Ley de los Grandes Números, que sugiere que a
medida que aumenta el tamaño de la muestra (en este caso, el número de 
votantes), las tendencias se vuelven más consistentes.

Adicionalmente, es posible que haya una variable no observada,
conocida como "Omitted Variable Bias" (sesgo por variable omitida), 
como el número de votantes que no acudió a votar, la cual podría estar
reflejando la verdadera tendencia de votos nulos y debería ser considerada 
en nuestro análisis.

```{r}
#### relationship between null votes and time (by minutes)
df_muestra |> 
    mutate(
        TIMESTAMP = str_c(ANIO, MES, DIA, HORA, MINUTOS, sep = "-") |> 
            lubridate::ymd_hm()
    ) |> 
    group_by(TIMESTAMP) |>
    summarise(
        PERCENT_NULL = sum(NULOS) / sum(TOTAL)
    ) |>
    ggplot(aes(x = TIMESTAMP, y = PERCENT_NULL)) +
    geom_point(color = "steelblue", alpha = 0.5) +
    geom_smooth(method = "loess", color = "darkred", se = FALSE) +
    scale_x_datetime(date_breaks = "1 hour", date_labels = "%H:%M") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_minimal() +
    ggtitle("Porcentaje de votos nulos vs tiempo", "Por casilla") +
    labs(x = "Tiempo", y = "Porcentaje de votos nulos")

# there doesnt seem to be a relationship between null votes and time but some outliers    

# notes about outliers #
# There are two big outlier groups: the ones which are zero and the ones bigger than 25% (to say a number)
# It could be that the ones which are zero are casillas with very few voters and the ones bigger than 25%
# are atypical casillas with a lot of null votes

# the second thing is that there are some states: cdmx, edo mex and veracruz who have an atypical behavior
# with respect to rest of the states

# about handling outliers #
# I would first analyze which states and poll booths have 0 null votes ore more than 25% null votes.
# For the first group, I would try to unbias by inputating the null votes with a sample of poll booths with percent of
# null votes greater than 0. 
# For the second group, I would try to do a separete analysis for those states and poll booths (the ones greater than 25%)

# Indepently of the method, it is true that this outliers of the "conteo rapido" bias the results. Maybe it will be appropiate
# to use a different statistical perspective, like bayesian inference, to handle this outliers with prior information.
# For example, we could use the results of the last election to inputate the null votes of the "conteo rapido" of this election
# and update the prior with the results of the "conteo rapido" of this election

```

No parece existir una relación clara entre los votos nulos y el factor temporal,
sin embargo, identificamos la presencia de valores atípicos que requieren 
nuestra atención.

Consideraciones sobre los valores atípicos:
Destacamos dos grupos significativos de valores atípicos: aquellos que se 
sitúan en cero y aquellos que superan el 25% (aproximadamente). Los valores
nulos iguales a cero posiblemente corresponden a casillas con una cantidad 
muy reducida de votantes, mientras que aquellos que superan el 25% podrían 
indicar casillas inusuales con un número considerable de votos nulos.

Además, observamos un comportamiento inusual en algunos estados, como la Ciudad
de México (CDMX), el Estado de México (Edo Mex) y Veracruz, en comparación con
el resto de los estados.

En cuanto a la gestión de los valores atípicos:
En primer lugar, sugiero llevar a cabo un análisis detallado para identificar
los estados y las casillas electorales que registran valores nulos iguales a 
cero o superiores al 25%. Para el primer grupo, podríamos considerar mitigar el
sesgo imputando los votos nulos utilizando una muestra de casillas con un 
porcentaje de votos nulos mayor que cero.

Para el segundo grupo, deberíamos explorar la posibilidad de realizar un
análisis por separado para aquellos estados y casillas electorales que superan
el 25% de votos nulos.

Independientemente del enfoque seleccionado, es importante reconocer
que estos valores atípicos en el "conteo rápido" pueden influir en los 
resultados. Por lo tanto, podría ser adecuado adoptar una perspectiva
estadística diferente, como la inferencia bayesiana, para abordar estos valores 
atípicos mediante la incorporación de información previa. Por ejemplo, 
podríamos utilizar los resultados de la elección anterior para imputar 
los votos nulos del "conteo rápido" de la presente elección y actualizar esta
información previa con los resultados actuales del "conteo rápido".







